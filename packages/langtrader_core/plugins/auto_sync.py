# packages/langtrader_core/plugins/auto_sync.py
"""
æ’ä»¶è‡ªåŠ¨åŒæ­¥æ¨¡å—
åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å°†æ’ä»¶åŒæ­¥åˆ°æ•°æ®åº“ï¼Œæ”¯æŒè¾¹è‡ªåŠ¨åˆ›å»ºå’Œæ¡ä»¶è¾¹
"""
import threading
import uuid
from typing import Dict, Any
from sqlmodel import Session
from langtrader_core.plugins.registry import registry
from langtrader_core.data.repositories.workflow import WorkflowRepository
from langtrader_core.plugins.protocol import NodeMetadata
from langtrader_core.utils import get_logger

logger = get_logger("plugin_auto_sync")


class PluginAutoSync:
    """
    æ’ä»¶è‡ªåŠ¨åŒæ­¥å™¨
    åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å°†æ–°æ’ä»¶æ³¨å†Œåˆ°æ•°æ®åº“
    """

    # class lock
    _local_locks = {}
    _lock_creation_lock = threading.Lock()
    
    def __init__(self, session: Session):
        self.session = session
        self.workflow_repo = WorkflowRepository(session)
        self.lock_owner = f"bot_{uuid.uuid4().hex[:8]}"
    
    @classmethod
    def _get_lock(cls, workflow_id: int) -> threading.Lock:
        """
        è·å– workflow é”ï¼ˆçº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼ï¼‰
        
        Args:
            workflow_id: Workflow ID
            
        Returns:
            è¯¥ workflow ä¸“ç”¨çš„é”å¯¹è±¡
        """
        if workflow_id not in cls._local_locks:
            with cls._lock_creation_lock:
                # åŒé‡æ£€æŸ¥
                if workflow_id not in cls._local_locks:
                    cls._local_locks[workflow_id] = threading.Lock()
                    logger.debug(f"ğŸ”’ Created lock for workflow {workflow_id}")
        
        return cls._local_locks[workflow_id]
    
    def sync_if_needed(self, workflow_id: int) -> Dict[str, int]:
        """
        å¢é‡åŒæ­¥æ’ä»¶åˆ°æ•°æ®åº“ï¼ˆå¹‚ç­‰æ“ä½œï¼Œçº¿ç¨‹å®‰å…¨ï¼‰
        
        Args:
            workflow_id: ç›®æ ‡ workflow ID
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯ {"existing": 4, "added": 1, "failed": 0}
        """
        # ğŸ”’ è·å– workflow çº§åˆ«çš„é”
        lock = self._get_lock(workflow_id)
        
        with lock:
            logger.debug(f"ğŸ”’ Acquired sync lock for workflow {workflow_id}")
            
            stats = {"existing": 0, "added": 0, "failed": 0, "edges_created": 0}
            
            try:
                # è·å–å·¥ä½œæµ
                workflow = self.workflow_repo.get_workflow(workflow_id)
                if not workflow:
                    logger.warning(f"âš ï¸  Workflow {workflow_id} not found, skipping auto-sync")
                    return stats
                
                # è·å–å·²æ³¨å†Œçš„æ’ä»¶
                discovered_plugins = registry._metadata  # {name: NodeMetadata}
                existing_nodes = {node.plugin_name: node for node in workflow.nodes}
                
                # æ‰¾å‡ºæ–°æ’ä»¶
                new_plugins = []
                for plugin_name, metadata in discovered_plugins.items():
                    if not metadata.auto_register:
                        continue
                    
                    if plugin_name in existing_nodes:
                        stats["existing"] += 1
                    else:
                        new_plugins.append((plugin_name, metadata))
                
                # å¦‚æœæ²¡æœ‰æ–°æ’ä»¶
                if not new_plugins:
                    logger.debug(f"âœ“ All {stats['existing']} plugins already registered")
                    # ğŸ¯ å³ä½¿æ²¡æœ‰æ–°æ’ä»¶ï¼Œä¹Ÿæ£€æŸ¥è¾¹æ˜¯å¦éœ€è¦åˆ›å»º
                    workflow = self.workflow_repo.get_workflow(workflow_id)
                    if not workflow.edges and len(workflow.nodes) > 0:
                        logger.info(f"ğŸ”— No edges found, creating initial edges...")
                        initial_edges = self._create_initial_edges(workflow_id)
                        stats["edges_created"] += initial_edges
                    return stats
                
                # ğŸ¯ æ”¹è¿›ï¼šåˆ†ä¸¤ä¸ªé˜¶æ®µ
                # é˜¶æ®µ1ï¼šå…ˆåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¸åˆ›å»ºè¾¹ï¼‰
                logger.info(f"ğŸ”„ Phase 1: Creating {len(new_plugins)} nodes...")
                
                for plugin_name, metadata in new_plugins:
                    try:
                        self._create_node_only(workflow_id, metadata)
                        stats["added"] += 1
                        logger.info(f"âœ… Created node: {plugin_name} (order={metadata.suggested_order})")
                    except Exception as e:
                        stats["failed"] += 1
                        logger.error(f"âŒ Failed to create node '{plugin_name}': {e}")
                
                # é˜¶æ®µ2ï¼šç»Ÿä¸€åˆ›å»ºæ‰€æœ‰è¾¹
                if stats["added"] > 0:
                    logger.info(f"ğŸ”„ Phase 2: Creating edges for all nodes...")
                    workflow = self.workflow_repo.get_workflow(workflow_id)  # é‡æ–°åŠ è½½
                    
                    if not workflow.edges:
                        # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåˆ›å»ºå®Œæ•´çš„åˆå§‹è¾¹
                        logger.info(f"   No existing edges, creating complete edge set...")
                        edges_count = self._create_initial_edges(workflow_id)
                        stats["edges_created"] += edges_count
                    else:
                        # å¦‚æœæœ‰è¾¹ï¼Œä¸ºæ–°èŠ‚ç‚¹æ’å…¥è¾¹
                        logger.info(f"   Existing edges found, inserting new nodes...")
                        for plugin_name, metadata in new_plugins:
                            try:
                                edges_count = self._connect_node(workflow_id, plugin_name, metadata)
                                stats["edges_created"] += edges_count
                            except Exception as e:
                                logger.error(f"âŒ Failed to connect '{plugin_name}': {e}")
                
                if stats["added"] > 0:
                    logger.info(f"âœ… Auto-sync completed: {stats['added']} plugins, {stats['edges_created']} edges")
                
            except Exception as e:
                logger.error(f"âŒ Auto-sync failed: {e}")
                stats["failed"] += 1
            
            logger.debug(f"ğŸ”“ Released sync lock for workflow {workflow_id}")
            return stats
    
    def _create_node_only(self, workflow_id: int, metadata: NodeMetadata):
        """åªåˆ›å»ºèŠ‚ç‚¹ï¼Œä¸åˆ›å»ºè¾¹"""
        workflow = self.workflow_repo.get_workflow(workflow_id)
        
        # è®¡ç®—æ‰§è¡Œé¡ºåº
        if metadata.suggested_order is not None:
            execution_order = metadata.suggested_order
        else:
            max_order = max([node.execution_order for node in workflow.nodes], default=0)
            execution_order = max_order + 1
        
        # åˆ›å»ºèŠ‚ç‚¹
        node = self.workflow_repo.add_node(
            workflow_id=workflow_id,
            name=metadata.name,
            plugin_name=metadata.name,
            enabled=True,
            execution_order=execution_order,
            config=metadata.default_config
        )
        
        logger.debug(f"   Created node: {node.name} (order={execution_order})")
    
    def _connect_node(self, workflow_id: int, plugin_name: str, metadata: NodeMetadata) -> int:
        """ä¸ºå•ä¸ªèŠ‚ç‚¹åˆ›å»ºè¾¹è¿æ¥"""
        workflow = self.workflow_repo.get_workflow(workflow_id)
        
        if metadata.is_conditional and metadata.conditional_routes:
            # æ¡ä»¶èŠ‚ç‚¹
            return self._create_conditional_edges(workflow_id, plugin_name, metadata)
        elif metadata.insert_after:
            # æ™®é€šèŠ‚ç‚¹
            return self._insert_after(workflow, plugin_name, metadata.insert_after)
        elif metadata.insert_before:
            return self._insert_before(workflow, plugin_name, metadata.insert_before)
        
        return 0
    
    
    def _create_conditional_edges(self, workflow_id: int, node_name: str, metadata: NodeMetadata) -> int:
        """
        åˆ›å»ºæ¡ä»¶è¾¹
        
        Returns:
            åˆ›å»ºçš„è¾¹æ•°é‡
        """
        count = 0
        
        # ä¸ºæ¯ä¸ªæ¡ä»¶è·¯ç”±åˆ›å»ºè¾¹
        for condition_value, target_node in metadata.conditional_routes.items():
            try:
                self.workflow_repo.add_edge(
                    workflow_id=workflow_id,
                    from_node=node_name,
                    to_node=target_node,
                    condition=condition_value
                )
                logger.info(f"   âœ… Conditional edge: {node_name} -[{condition_value}]-> {target_node}")
                count += 1
            except Exception as e:
                logger.error(f"   âŒ Failed to create conditional edge: {e}")
        
        # ğŸ¯ è¿˜éœ€è¦åˆ›å»ºåˆ°è¾¾æ­¤æ¡ä»¶èŠ‚ç‚¹çš„è¾¹
        if metadata.insert_after:
            upstream_count = self._connect_upstream(workflow_id, node_name, metadata.insert_after)
            count += upstream_count
        
        return count
    
    def _insert_after(self, workflow, node_name: str, after_node: str) -> int:
        """
        å°†èŠ‚ç‚¹æ’å…¥åˆ°æŒ‡å®šèŠ‚ç‚¹ä¹‹å
        
        Returns:
            åˆ›å»ºçš„è¾¹æ•°é‡
        """
        count = 0
        
        logger.info(f"   Attempting to insert '{node_name}' after '{after_node}'")
        
        # ğŸ¯ æ”¹è¿›ï¼šä¼˜å…ˆä»ç°æœ‰è¾¹æŸ¥æ‰¾ï¼Œå¤±è´¥åˆ™ä» execution_order æ¨æ–­
        downstream = self._find_downstream(workflow, after_node)
        
        logger.info(f"   Found downstream: {downstream}")
        
        if not downstream:
            logger.warning(f"   Cannot determine downstream of '{after_node}', edge creation skipped")
            return 0
        
        # åˆ é™¤æ—§è¾¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        for edge in workflow.edges:
            if edge.from_node == after_node and edge.to_node == downstream:
                self.session.delete(edge)
                self.session.commit()
                logger.debug(f"   Removed old edge: {after_node} -> {downstream}")
                break
        
        # æ·»åŠ æ–°è¾¹
        try:
            self.workflow_repo.add_edge(workflow.id, after_node, node_name)
            count += 1
            self.workflow_repo.add_edge(workflow.id, node_name, downstream)
            count += 1
            logger.info(f"   âœ… Connected: {after_node} -> {node_name} -> {downstream}")
        except Exception as e:
            logger.error(f"   âŒ Failed to create edges: {e}")
        
        return count
    
    def _insert_before(self, workflow, node_name: str, before_node: str) -> int:
        """
        å°†èŠ‚ç‚¹æ’å…¥åˆ°æŒ‡å®šèŠ‚ç‚¹ä¹‹å‰
        
        Returns:
            åˆ›å»ºçš„è¾¹æ•°é‡
        """
        count = 0
        
        logger.info(f"   Attempting to insert '{node_name}' before '{before_node}'")
        
        # ğŸ¯ æ”¹è¿›ï¼šä¼˜å…ˆä»ç°æœ‰è¾¹æŸ¥æ‰¾ï¼Œå¤±è´¥åˆ™ä» execution_order æ¨æ–­
        upstream = self._find_upstream(workflow, before_node)
        
        logger.info(f"   Found upstream: {upstream}")
        
        if not upstream:
            logger.warning(f"   Cannot determine upstream of '{before_node}', edge creation skipped")
            return 0
        
        # åˆ é™¤æ—§è¾¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        for edge in workflow.edges:
            if edge.from_node == upstream and edge.to_node == before_node:
                self.session.delete(edge)
                self.session.commit()
                logger.debug(f"   Removed old edge: {upstream} -> {before_node}")
                break
        
        # æ·»åŠ æ–°è¾¹
        try:
            self.workflow_repo.add_edge(workflow.id, upstream, node_name)
            count += 1
            self.workflow_repo.add_edge(workflow.id, node_name, before_node)
            count += 1
            logger.info(f"   âœ… Connected: {upstream} -> {node_name} -> {before_node}")
        except Exception as e:
            logger.error(f"   âŒ Failed to create edges: {e}")
        
        return count
    
    def _connect_upstream(self, workflow_id: int, node_name: str, upstream_node: str) -> int:
        """
        ä»…åˆ›å»ºä¸Šæ¸¸åˆ°å½“å‰èŠ‚ç‚¹çš„è¾¹ï¼ˆç”¨äºæ¡ä»¶èŠ‚ç‚¹ï¼‰
        
        Returns:
            åˆ›å»ºçš„è¾¹æ•°é‡
        """
        try:
            self.workflow_repo.add_edge(workflow_id, upstream_node, node_name)
            logger.debug(f"   âœ… Upstream edge: {upstream_node} -> {node_name}")
            return 1
        except Exception as e:
            logger.error(f"   âŒ Failed to create upstream edge: {e}")
            return 0
    
    def _find_downstream(self, workflow, node_name: str) -> str:
        """
        æ™ºèƒ½æŸ¥æ‰¾ä¸‹æ¸¸èŠ‚ç‚¹
        1. ä¼˜å…ˆä»ç°æœ‰è¾¹æŸ¥æ‰¾
        2. å¤±è´¥åˆ™ä» execution_order æ¨æ–­
        """
        logger.debug(f"   _find_downstream: looking for downstream of '{node_name}'")
        
        # æ–¹æ³•1ï¼šä»ç°æœ‰è¾¹æŸ¥æ‰¾
        for edge in workflow.edges:
            if edge.from_node == node_name:
                logger.debug(f"   Found from edges: {edge.to_node}")
                return edge.to_node
        
        # æ–¹æ³•2ï¼šä» execution_order æ¨æ–­
        current_order = None
        for node in workflow.nodes:
            if node.name == node_name:
                current_order = node.execution_order
                break
        
        logger.debug(f"   Node '{node_name}' has order={current_order}")
        
        if current_order is None:
            logger.warning(f"   Node '{node_name}' not found in workflow!")
            return None
        
        # æ‰¾åˆ°æ‰§è¡Œé¡ºåºæœ€æ¥è¿‘çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        next_nodes = [n for n in workflow.nodes if n.execution_order > current_order]
        
        logger.debug(f"   Found {len(next_nodes)} nodes with order > {current_order}")
        for n in next_nodes[:3]:
            logger.debug(f"     - {n.name} (order={n.execution_order})")
        
        if not next_nodes:
            logger.debug(f"   No downstream nodes, returning END")
            return "END"
        
        next_nodes.sort(key=lambda n: n.execution_order)
        downstream = next_nodes[0].name
        
        logger.debug(f"   Returning downstream: {downstream}")
        
        return downstream
    
    def _find_upstream(self, workflow, node_name: str) -> str:
        """
        æ™ºèƒ½æŸ¥æ‰¾ä¸Šæ¸¸èŠ‚ç‚¹
        1. ä¼˜å…ˆä»ç°æœ‰è¾¹æŸ¥æ‰¾
        2. å¤±è´¥åˆ™ä» execution_order æ¨æ–­
        """
        logger.debug(f"   _find_upstream: looking for upstream of '{node_name}'")
        
        # æ–¹æ³•1ï¼šä»ç°æœ‰è¾¹æŸ¥æ‰¾
        for edge in workflow.edges:
            if edge.to_node == node_name:
                logger.debug(f"   Found from edges: {edge.from_node}")
                return edge.from_node
        
        # æ–¹æ³•2ï¼šä» execution_order æ¨æ–­
        current_order = None
        for node in workflow.nodes:
            if node.name == node_name:
                current_order = node.execution_order
                break
        
        logger.debug(f"   Node '{node_name}' has order={current_order}")
        
        if current_order is None:
            logger.warning(f"   Node '{node_name}' not found in workflow!")
            return None
        
        # æ‰¾åˆ°æ‰§è¡Œé¡ºåºæœ€æ¥è¿‘çš„ä¸Šä¸€ä¸ªèŠ‚ç‚¹
        prev_nodes = [n for n in workflow.nodes if n.execution_order < current_order]
        
        logger.debug(f"   Found {len(prev_nodes)} nodes with order < {current_order}")
        
        if not prev_nodes:
            logger.debug(f"   No upstream nodes, returning START")
            return "START"
        
        prev_nodes.sort(key=lambda n: n.execution_order, reverse=True)
        upstream = prev_nodes[0].name
        
        logger.debug(f"   Returning upstream: {upstream}")
        
        return upstream
    
    def _create_initial_edges(self, workflow_id: int) -> int:
        """
        ä¸ºæ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºåˆå§‹è¾¹ï¼ˆå½“ workflow.edges ä¸ºç©ºæ—¶ï¼‰
        åŸºäº execution_order åˆ›å»ºçº¿æ€§æµç¨‹
        
        Returns:
            åˆ›å»ºçš„è¾¹æ•°é‡
        """
        workflow = self.workflow_repo.get_workflow(workflow_id)
        count = 0
        
        # è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ŒæŒ‰ execution_order æ’åº
        sorted_nodes = sorted(workflow.nodes, key=lambda n: n.execution_order)
        
        if len(sorted_nodes) == 0:
            logger.warning("   No nodes to connect")
            return 0
        
        logger.info(f"   Creating initial edges for {len(sorted_nodes)} nodes...")
        
        # START -> first_node
        try:
            self.workflow_repo.add_edge(workflow_id, 'START', sorted_nodes[0].name)
            count += 1
            logger.info(f"   Created edge: START -> {sorted_nodes[0].name}")
        except Exception as e:
            logger.debug(f"   Edge START -> {sorted_nodes[0].name} may already exist: {e}")
        
        # node[i] -> node[i+1]
        for i in range(len(sorted_nodes) - 1):
            try:
                self.workflow_repo.add_edge(
                    workflow_id, 
                    sorted_nodes[i].name, 
                    sorted_nodes[i + 1].name
                )
                count += 1
                logger.info(f"   Created edge: {sorted_nodes[i].name} -> {sorted_nodes[i + 1].name}")
            except Exception as e:
                logger.debug(f"   Edge {sorted_nodes[i].name} -> {sorted_nodes[i + 1].name} may already exist: {e}")
        
        # last_node -> END
        try:
            self.workflow_repo.add_edge(workflow_id, sorted_nodes[-1].name, 'END')
            count += 1
            logger.info(f"   Created edge: {sorted_nodes[-1].name} -> END")
        except Exception as e:
            logger.debug(f"   Edge {sorted_nodes[-1].name} -> END may already exist: {e}")
        
        logger.info(f"   âœ… Created {count} initial edges")
        return count


# å…¨å±€ä¾¿æ·å‡½æ•°
def auto_sync_plugins(session: Session, workflow_id: int) -> Dict[str, int]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè‡ªåŠ¨åŒæ­¥æ’ä»¶
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        from langtrader_core.plugins.auto_sync import auto_sync_plugins
        stats = auto_sync_plugins(session, workflow_id=1)
    """
    syncer = PluginAutoSync(session)
    return syncer.sync_if_needed(workflow_id)