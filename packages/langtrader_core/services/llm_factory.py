# packages/langtrader_core/services/llm_factory.py

from typing import Optional
from langtrader_core.utils import get_logger
from langchain_core.language_models import BaseChatModel

logger = get_logger("llm_factory")

try:
    from langchain_openai import ChatOpenAI
    from langchain_anthropic import ChatAnthropic
    from langchain_ollama import ChatOllama
except ImportError as e:
    logger.warning(f"LangChainå¯¼å…¥å¤±è´¥: {e}")
    ChatOpenAI = None
    ChatAnthropic = None
    ChatOllama = None

from sqlmodel import Session

from langtrader_core.data.repositories.llm_config import LLMConfigRepository
from langtrader_core.data.models.llm_config import LLMConfig




class LLMFactory:
    """
    LLM å·¥å‚ç±»
    æ ¹æ®é…ç½®åˆ›å»ºä¸åŒçš„ LLM å®ä¾‹
    """
    
    def __init__(self, session: Session):
        self.session = session
        self.repo = LLMConfigRepository(session)
    
    def create_from_config(self, config: LLMConfig) -> BaseChatModel:
        """
        æ ¹æ®é…ç½®åˆ›å»º LLM å®ä¾‹
        """
        if not config.is_enabled:
            logger.error(f"ğŸ™… LLM config '{config.name}' is disabled")
            raise ValueError(f"LLM config '{config.name}' is disabled")
        
        provider = config.provider.lower()
        kwargs = config.to_langchain_kwargs()
        
        logger.info(f"Creating LLM: {config.display_name or config.name} ({config.provider}/{config.model_name})")
        logger.debug(f"LLM kwargs: {kwargs}")
        
        if provider == "openai":
            if not ChatOpenAI:
                logger.error("ğŸ™… OpenAI æœªå®‰è£…")
                raise ValueError("OpenAI æœªå®‰è£…")
            return ChatOpenAI(**kwargs)
        
        elif provider == "anthropic":
            if not ChatAnthropic:
                logger.error("ğŸ™… Anthropic æœªå®‰è£…")
                raise ValueError("Anthropic æœªå®‰è£…")
            return ChatAnthropic(**kwargs)
        
        elif provider == "ollama":
            # Ollama æœ¬åœ°æ¨¡å‹
            if not ChatOllama:
                logger.error("ğŸ™… Ollama æœªå®‰è£…")
                raise ValueError("Ollama æœªå®‰è£…")
            return ChatOllama(**kwargs)
        
        else:
            # other models can try using openai api first
            try:
                return ChatOpenAI(**kwargs)
            except Exception as e:
                logger.error(f"Failed to create LLM: {e}")
                raise ValueError(f"Failed to create LLM: {e}")
    
    def create_from_id(self, config_id: int) -> BaseChatModel:
        """æ ¹æ®é…ç½® ID åˆ›å»º LLM"""
        config = self.repo.get_by_id(config_id)
        if not config:
            raise ValueError(f"LLM config not found: id={config_id}")
        return self.create_from_config(config)
    
    def create_from_name(self, name: str) -> BaseChatModel:
        """æ ¹æ®é…ç½®åç§°åˆ›å»º LLM"""
        config = self.repo.get_by_name(name)
        if not config:
            raise ValueError(f"LLM config not found: name={name}")
        return self.create_from_config(config)
    
    def create_default(self) -> BaseChatModel:
        """åˆ›å»ºé»˜è®¤ LLM"""
        config = self.repo.get_default()
        if not config:
            raise ValueError("No default LLM config found")
        return self.create_from_config(config)
    
    def create_for_bot(self, bot_id: int, session: Optional[Session] = None) -> BaseChatModel:
        """
        ä¸ºæŒ‡å®š Bot åˆ›å»º LLM
        ä¼˜å…ˆä½¿ç”¨ Bot é…ç½®çš„ LLMï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤ LLM
        """
        from langtrader_core.data.repositories.bot import BotRepository
        
        bot_session = session or self.session
        bot_repo = BotRepository(bot_session)
        bot = bot_repo.get_by_id(bot_id)
        
        if not bot:
            raise ValueError(f"Bot not found: id={bot_id}")
        
        # ä¼˜å…ˆä½¿ç”¨ Bot é…ç½®çš„ LLM
        if bot.llm_id:
            logger.info(f"Using bot-specific LLM: bot_id={bot_id}, llm_id={bot.llm_id}")
            return self.create_from_id(bot.llm_id)
        
        # å¦åˆ™ä½¿ç”¨é»˜è®¤ LLM
        logger.info(f"Using default LLM for bot: bot_id={bot_id}")
        return self.create_default()