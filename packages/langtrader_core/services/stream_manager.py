"""
åŠ¨æ€ WebSocket æµç®¡ç†å™¨
æ ¹æ®é€‰å¸ç»“æœè‡ªåŠ¨è®¢é˜…/å–æ¶ˆè®¢é˜…ï¼Œä¼˜åŒ–èµ„æºä½¿ç”¨å’Œæ•°æ®å®æ—¶æ€§
"""
from typing import Dict, Set, Optional, List
import asyncio
from collections import defaultdict
import time
from langtrader_core.services.trader import Trader
from langtrader_core.services.cache import Cache
from langtrader_core.utils import get_logger

logger = get_logger("stream_manager")


class DynamicStreamManager:
    """
    åŠ¨æ€ WebSocket æµç®¡ç†å™¨
    - æ ¹æ®é€‰å¸ç»“æœè‡ªåŠ¨è®¢é˜…/å–æ¶ˆè®¢é˜…
    - æ”¯æŒå¤šæ—¶é—´æ¡†æ¶
    - è‡ªåŠ¨ç»´æŠ¤è¿æ¥å’Œé‡è¿
    """
    
    def __init__(self, trader: Trader):
        self.trader = trader
        self.cache = Cache()
        
        # è®¢é˜…çŠ¶æ€è¿½è¸ª
        self.active_subscriptions: Dict[str, Dict[str, asyncio.Task]] = defaultdict(dict)
        # æ ¼å¼: {symbol: {timeframe: task}}
        
        # è®¢é˜…é”ï¼ˆé¿å…é‡å¤è®¢é˜…ï¼‰
        self._subscription_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)
        
        # å¤±è´¥å¸ç§è¿½è¸ªï¼ˆç”¨äºä¸‹ä¸€è½®é‡è¯•ï¼‰
        self._failed_symbols: Set[str] = set()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_subscribed': 0,
            'total_unsubscribed': 0,
            'active_streams': 0,
            'reconnections': 0,
            'failed_retries': 0
        }
    
    async def sync_subscriptions(
        self, 
        new_symbols: List[str], 
        timeframes: List[str] = ['3m']
    ):
        """
        åŒæ­¥è®¢é˜…åˆ—è¡¨ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        æ ¹æ®æ–°çš„å¸ç§åˆ—è¡¨ï¼Œè‡ªåŠ¨æ·»åŠ /åˆ é™¤è®¢é˜…
        
        Args:
            new_symbols: æœ€æ–°çš„é€‰å¸ç»“æœ
            timeframes: è¦è®¢é˜…çš„æ—¶é—´æ¡†æ¶åˆ—è¡¨
        """
        new_set = set(new_symbols)
        current_set = set(self.active_subscriptions.keys())
        
        # å°†ä¹‹å‰å¤±è´¥çš„å¸ç§ï¼ˆå¦‚æœä»åœ¨å€™é€‰åˆ—è¡¨ä¸­ï¼‰åŠ å…¥é‡æ–°è®¢é˜…
        retry_symbols = self._failed_symbols & new_set
        if retry_symbols:
            logger.info(f"ğŸ”„ Re-attempting {len(retry_symbols)} previously failed symbols")
            self._failed_symbols.clear()
        
        # è®¡ç®—å·®å¼‚ï¼ˆåŒ…å«éœ€è¦é‡è¯•çš„å¸ç§ï¼‰
        to_subscribe = (new_set - current_set) | retry_symbols
        to_unsubscribe = current_set - new_set
        to_keep = current_set & new_set - retry_symbols
        
        logger.info(f"ğŸ“Š Subscription sync: "
                   f"+{len(to_subscribe)} "
                   f"-{len(to_unsubscribe)} "
                   f"={len(to_keep)}")
        
        # å¹¶å‘å¤„ç†è®¢é˜…å˜åŒ–
        tasks = []
        
        # 1. å–æ¶ˆä¸éœ€è¦çš„è®¢é˜…
        for symbol in to_unsubscribe:
            tasks.append(self._unsubscribe_symbol(symbol))
        
        # 2. æ·»åŠ æ–°è®¢é˜…ï¼ˆå¸¦é€Ÿç‡é™åˆ¶ï¼‰
        for idx, symbol in enumerate(to_subscribe):
            for timeframe in timeframes:
                # æ·»åŠ å°å»¶è¿Ÿé¿å…è®¢é˜…é£æš´
                if idx > 0:
                    await asyncio.sleep(0.1)
                tasks.append(self._subscribe(symbol, timeframe))
        
        # ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ç»Ÿè®¡ç»“æœ
            errors = [r for r in results if isinstance(r, Exception)]
            if errors:
                logger.warning(f"âš ï¸  {len(errors)} subscription operations failed")
                for error in errors:
                    logger.debug(f"Error detail: {error}")
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['active_streams'] = len(self.active_subscriptions)
        logger.info(f"âœ… Active streams: {self.stats['active_streams']} symbols")
        
        # æ˜¾ç¤ºå½“å‰è®¢é˜…çš„å¸ç§åˆ—è¡¨
        if self.active_subscriptions:
            symbols_list = list(self.active_subscriptions.keys())[:5]  # æ˜¾ç¤ºå‰5ä¸ª
            if len(self.active_subscriptions) > 5:
                symbols_list.append(f"... (+{len(self.active_subscriptions) - 5} more)")
            logger.info(f"   Symbols: {', '.join(symbols_list)}")
    
    async def _subscribe(self, symbol: str, timeframe: str):
        """
        è®¢é˜…å•ä¸ªå¸ç§çš„ OHLCV æµ
        é¦–æ¬¡è®¢é˜…æ—¶ä¼šä½¿ç”¨ REST API é¢„å¡«å……ç¼“å­˜ï¼Œé¿å…å†·å¯åŠ¨é—®é¢˜
        """
        async with self._subscription_locks[f"{symbol}:{timeframe}"]:
            # æ£€æŸ¥æ˜¯å¦å·²è®¢é˜…
            if timeframe in self.active_subscriptions.get(symbol, {}):
                logger.debug(f"Already subscribed: {symbol} {timeframe}")
                return
            
            logger.info(f"ğŸ“¡ Subscribing: {symbol} {timeframe}")
            
            try:
                # âœ… é¦–æ¬¡è®¢é˜…ï¼šå…ˆç”¨ REST API é¢„å¡«å……ç¼“å­˜ï¼ˆé¿å…å†·å¯åŠ¨ï¼‰
                cache_key = f'{symbol}:{timeframe}:100'
                cached_data = self.cache.get(f'ohlcv_{timeframe}', cache_key)
                
                if not cached_data:
                    logger.debug(f"ğŸ”„ Pre-filling cache for {symbol} {timeframe}")
                    try:
                        initial_ohlcv = await self.trader.fetch_ohlcv(symbol, timeframe, limit=100)
                        if initial_ohlcv:
                            self.cache.set(f'ohlcv_{timeframe}', initial_ohlcv, cache_key)
                            logger.debug(f"âœ… Cache pre-filled: {symbol} {timeframe} ({len(initial_ohlcv)} candles)")
                    except Exception as e:
                        logger.warning(f"Failed to pre-fill cache for {symbol}: {e}")
                
                # åˆ›å»º WebSocket ç›‘å¬ä»»åŠ¡
                task = asyncio.create_task(
                    self._watch_stream(symbol, timeframe),
                    name=f"watch_{symbol}_{timeframe}"
                )
                
                self.active_subscriptions[symbol][timeframe] = task
                self.stats['total_subscribed'] += 1
                
            except Exception as e:
                logger.error(f"Failed to subscribe {symbol} {timeframe}: {e}")
                raise
    
    async def _unsubscribe_symbol(self, symbol: str):
        """
        å–æ¶ˆè®¢é˜…æ•´ä¸ªå¸ç§çš„æ‰€æœ‰æ—¶é—´æ¡†æ¶
        """
        if symbol not in self.active_subscriptions:
            return
        
        logger.info(f"ğŸ”Œ Unsubscribing: {symbol}")
        
        # å–æ¶ˆæ‰€æœ‰æ—¶é—´æ¡†æ¶çš„è®¢é˜…
        tasks = self.active_subscriptions[symbol]
        
        for timeframe, task in tasks.items():
            try:
                # è°ƒç”¨ CCXT çš„ unwatch_ohlcvï¼ˆå¦‚æœæ”¯æŒï¼‰
                if hasattr(self.trader.exchange, 'unwatch_ohlcv'):
                    try:
                        await self.trader.exchange.unwatch_ohlcv(symbol, timeframe)
                        logger.debug(f"Called unwatch_ohlcv for {symbol} {timeframe}")
                    except Exception as e:
                        logger.debug(f"unwatch_ohlcv not supported or failed: {e}")
                
                # å–æ¶ˆåç¨‹ä»»åŠ¡
                if not task.done():
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        pass
                
                self.stats['total_unsubscribed'] += 1
                
            except Exception as e:
                logger.error(f"Error unsubscribing {symbol} {timeframe}: {e}")
        
        # ä»æ´»è·ƒåˆ—è¡¨ä¸­åˆ é™¤
        del self.active_subscriptions[symbol]
        
        # æ¸…ç†ç›¸å…³ç¼“å­˜
        self._cleanup_cache(symbol)
        
        # æ¸…ç†å¯¹åº”çš„è®¢é˜…é”ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰
        lock_keys_to_remove = [k for k in list(self._subscription_locks.keys()) 
                              if k.startswith(f"{symbol}:")]
        for key in lock_keys_to_remove:
            del self._subscription_locks[key]
        if lock_keys_to_remove:
            logger.debug(f"ğŸ”“ Cleaned up {len(lock_keys_to_remove)} locks for {symbol}")
    
    async def _watch_stream(self, symbol: str, timeframe: str):
        """
        æŒç»­ç›‘å¬å•ä¸ªå¸ç§çš„ OHLCV æµ
        æ”¯æŒè‡ªåŠ¨é‡è¿
        åªåœ¨Kçº¿å®Œæˆæ—¶æ›´æ–°ç¼“å­˜ï¼Œé¿å…ä½¿ç”¨æœªå®Œæˆçš„Kçº¿è®¡ç®—æŒ‡æ ‡
        """
        retry_count = 0
        max_retries = 5
        last_candle_time = None  # è·Ÿè¸ªæœ€åä¸€æ ¹å·²å®ŒæˆKçº¿çš„æ—¶é—´
        
        while True:
            try:
                logger.debug(f"ğŸ“Š Watching {symbol} {timeframe}...")
                
                # CCXT Pro çš„ watch_ohlcv ä¼šæŒç»­è¿”å›æ›´æ–°
                ohlcv = await self.trader.exchange.watch_ohlcv(symbol, timeframe)
                
                if not ohlcv or len(ohlcv) == 0:
                    continue
                
                # è·å–æœ€æ–°Kçº¿
                latest_candle = ohlcv[-1]
                candle_open_time = latest_candle[0]  # å¼€ç›˜æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                
                # è®¡ç®—Kçº¿å…³é—­æ—¶é—´
                timeframe_ms = self._timeframe_to_ms(timeframe)
                candle_close_time = candle_open_time + timeframe_ms
                current_time = int(time.time() * 1000)  # å½“å‰æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                
                # åˆ¤æ–­Kçº¿æ˜¯å¦å·²å®Œæˆ
                is_completed = current_time >= candle_close_time
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å®ŒæˆKçº¿ï¼ˆé¿å…é‡å¤æ›´æ–°åŒä¸€æ ¹Kçº¿ï¼‰
                is_new_candle = last_candle_time is None or candle_open_time > last_candle_time
                
                if is_completed and is_new_candle:
                    # Kçº¿å·²å®Œæˆï¼Œæ›´æ–°ç¼“å­˜
                    cache_key = f'{symbol}:{timeframe}:100'
                    self.cache.set(f'ohlcv_{timeframe}', ohlcv, cache_key)
                    
                    last_candle_time = candle_open_time
                    logger.debug(f"âœ… Updated completed candle: {symbol} {timeframe} at {candle_open_time}")
                elif not is_completed:
                    # âœ… å®æ—¶æ›´æ–°ï¼šå³ä½¿Kçº¿æœªå®Œæˆï¼Œä¹Ÿæ›´æ–°ç¼“å­˜ä»¥æä¾›æœ€æ–°ä»·æ ¼
                    cache_key = f'{symbol}:{timeframe}:100'
                    self.cache.set(f'ohlcv_{timeframe}', ohlcv, cache_key)
                    logger.debug(f"ğŸ“¡ Updated partial candle (real-time): {symbol} {timeframe} "
                               f"(close in {(candle_close_time - current_time) / 1000:.0f}s)")
                else:
                    # Kçº¿å·²å®Œæˆä½†ä¸æ˜¯æ–°Kçº¿ï¼Œè·³è¿‡æ›´æ–°
                    pass
                
                # æ—¥å¿—è®°å½•ï¼ˆé™ä½é¢‘ç‡ï¼Œé¿å…åˆ·å±ï¼‰
                if retry_count > 0:
                    logger.info(f"âœ… Reconnected: {symbol} {timeframe}")
                
                # é‡ç½®é‡è¯•è®¡æ•°
                retry_count = 0
                
            except asyncio.CancelledError:
                logger.info(f"Stream cancelled: {symbol} {timeframe}")
                break
                
            except Exception as e:
                retry_count += 1
                logger.error(f"âŒ Stream error {symbol} {timeframe}: {e} "
                           f"(retry {retry_count}/{max_retries})")
                
                if retry_count >= max_retries:
                    logger.error(f"Max retries reached for {symbol} {timeframe}, giving up")
                    # ä»æ´»è·ƒè®¢é˜…ä¸­ç§»é™¤
                    if symbol in self.active_subscriptions:
                        self.active_subscriptions[symbol].pop(timeframe, None)
                        if not self.active_subscriptions[symbol]:
                            del self.active_subscriptions[symbol]
                    
                    # æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¸‹ä¸€è½® sync_subscriptions æ—¶ä¼šå°è¯•é‡æ–°è®¢é˜…
                    self._failed_symbols.add(symbol)
                    self.stats['failed_retries'] += 1
                    logger.info(f"ğŸ“Œ Marked {symbol} for retry in next sync cycle")
                    break
                
                # æŒ‡æ•°é€€é¿é‡è¯•
                backoff_time = min(2 ** retry_count, 60)
                logger.info(f"Retrying in {backoff_time}s...")
                await asyncio.sleep(backoff_time)
                self.stats['reconnections'] += 1
    
    def _timeframe_to_ms(self, timeframe: str) -> int:
        """
        å°†æ—¶é—´æ¡†æ¶è½¬æ¢ä¸ºæ¯«ç§’
        
        Args:
            timeframe: æ—¶é—´æ¡†æ¶å­—ç¬¦ä¸²ï¼Œå¦‚ '3m', '1h', '1d'
            
        Returns:
            æ—¶é—´æ¡†æ¶å¯¹åº”çš„æ¯«ç§’æ•°
        """
        unit = timeframe[-1]
        value = int(timeframe[:-1])
        
        multipliers = {
            's': 1000,           # ç§’
            'm': 60 * 1000,      # åˆ†é’Ÿ
            'h': 3600 * 1000,    # å°æ—¶
            'd': 86400 * 1000,   # å¤©
            'w': 7 * 86400 * 1000,  # å‘¨
        }
        
        if unit not in multipliers:
            logger.warning(f"Unknown timeframe unit: {unit}, defaulting to minutes")
            return value * 60 * 1000
        
        return value * multipliers[unit]
    
    def _cleanup_cache(self, symbol: str):
        """æ¸…ç†å¸ç§ç›¸å…³çš„ç¼“å­˜"""
        for timeframe in ['3m', '4h', '1h', '15m']:
            cache_key = f'{symbol}:{timeframe}:100'
            try:
                # ä½¿ç”¨ Cache çš„ delete æ–¹æ³•æ¸…ç†
                self.cache.delete(f'ohlcv_{timeframe}', cache_key)
            except Exception as e:
                logger.debug(f"Cache cleanup error for {symbol}: {e}")
    
    async def get_latest_ohlcv(self, symbol: str, timeframe: str) -> Optional[list]:
        """
        è·å–æœ€æ–°çš„ OHLCV æ•°æ®
        ä¼˜å…ˆä»ç¼“å­˜è¯»å–ï¼ˆWebSocket å®æ—¶æ›´æ–°çš„ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            
        Returns:
            OHLCV æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å› None
        """
        cache_key = f'{symbol}:{timeframe}:100'
        data = self.cache.get(f'ohlcv_{timeframe}', cache_key)
        
        if data:
            logger.debug(f"Cache hit for {symbol} {timeframe}")
            return data
        
        # å¦‚æœç¼“å­˜æœªå‘½ä¸­ï¼Œå›é€€åˆ° REST API
        logger.warning(f"Cache miss for {symbol} {timeframe}, falling back to REST")
        try:
            return await self.trader.fetch_ohlcv(symbol, timeframe, limit=100)
        except Exception as e:
            logger.error(f"Failed to fetch OHLCV for {symbol} {timeframe}: {e}")
            return None
    
    async def shutdown(self):
        """
        ä¼˜é›…å…³é—­æ‰€æœ‰è®¢é˜…
        """
        logger.info("ğŸ›‘ Shutting down all streams...")
        
        symbols = list(self.active_subscriptions.keys())
        tasks = [self._unsubscribe_symbol(symbol) for symbol in symbols]
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        logger.info(f"âœ… Shutdown complete. Stats: {self.stats}")
    
    def get_stats(self) -> dict:
        """è·å–è®¢é˜…ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            'current_symbols': list(self.active_subscriptions.keys()),
            'subscriptions_detail': {
                symbol: list(subs.keys()) 
                for symbol, subs in self.active_subscriptions.items()
            }
        }

